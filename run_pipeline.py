import asyncio
import os
import yaml
import logging
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ê¸°ë³¸ ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ContentAutomationPipeline:
    def __init__(self, base_dir="./content-output"):
        self.base_dir = Path(base_dir)
        self.date_str = datetime.now().strftime("%y%m%d")
        self.output_dir = self.base_dir / self.date_str
        self.prompts = self._load_prompts()
        
        # API í‚¤ (ì‹¤ì œ ì‚¬ìš© ì‹œì ì—ì„œ ë¡œë“œ)
        self.perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        self.claude_api_key = os.getenv("CLAUDE_API_KEY")
        self.nano_banana_api_key = os.getenv("NANO_BANANA_API_KEY")
        # ... ë‹¤ë¥¸ API í‚¤ë“¤ë„ í•„ìš”ì— ë”°ë¼ ì¶”ê°€

    def _load_prompts(self):
        """prompts í´ë”ì—ì„œ .yaml í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        prompts = {}
        prompt_dir = Path("./prompts")
        if not prompt_dir.exists():
            logger.warning(f"í”„ë¡¬í”„íŠ¸ í´ë”({prompt_dir})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return prompts
            
        for prompt_file in prompt_dir.glob("*.yaml"):
            try:
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    prompts[prompt_file.stem] = yaml.safe_load(f)
                    logger.info(f"'{prompt_file.name}' í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"'{prompt_file.name}' í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return prompts

    def _save_result(self, step_name: str, file_name: str, content: str, lang: str = 'kr', extension: str = 'md'):
        """ê²°ê³¼ë¬¼ì„ ì§€ì •ëœ ê²½ë¡œì— íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        step_dir = self.output_dir / step_name
        step_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = step_dir / f"{file_name}.{extension}"
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            logger.info(f"ê²°ê³¼ë¬¼ì´ '{file_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"'{file_path}' íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    async def step1_research(self):
        """Step 1: ì½˜í…ì¸  ì†Œì¬ ì¡°ì‚¬ (Mockup)"""
        logger.info("Step 1: ì½˜í…ì¸  ì†Œì¬ ì¡°ì‚¬ ì‹œì‘...")
        prompt_data = self.prompts.get('prompt1-research', {})
        
        # --- Mockup ë¡œì§ ---
        # ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹ , í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ Mockup ê²°ê³¼ ìƒì„±
        # logger.info(f"API Key 'PERPLEXITY_API_KEY' ì‚¬ìš© ì˜ˆì •: {self.perplexity_api_key[:5]}...")
        logger.info("ì‹¤ì œ Perplexity API í˜¸ì¶œì€ ìƒëµí•©ë‹ˆë‹¤ (Mockup).")
        
        mock_result = f"""
# AI ê¸°ìˆ  ë™í–¥ ì¡°ì‚¬ (Mockup)

## ê°œìš”
- Perplexity APIë¥¼ í†µí•´ ìƒì„±ëœ Mockup ë°ì´í„°ì…ë‹ˆë‹¤.
- ì›ë³¸ í”„ë¡¬í”„íŠ¸ ì§ˆë¬¸: {prompt_data.get('query', 'N/A')}

## ì£¼ìš” ë™í–¥
1.  **ì´ˆê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „**: GPT-4, Gemini ë“± ë”ìš± ì •êµí•œ ëª¨ë¸ ë“±ì¥
2.  **ë©€í‹°ëª¨ë‹¬ AI**: í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ìŒì„±ì„ ë™ì‹œì— ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ê¸°ìˆ  í™•ì‚°
3.  **AI ìœ¤ë¦¬ ë° ì•ˆì „ì„±**: AIì˜ ì‚¬íšŒì  ì˜í–¥ì„ ê³ ë ¤í•œ ê·œì œ ë° ê¸°ìˆ ì  ë…¼ì˜ í™œë°œ
"""
        self._save_result("step1", "step1-research-kr", mock_result)
        logger.info("Step 1 ì™„ë£Œ.")
        return mock_result

    async def step2_structure(self, research_result: str):
        """Step 2: ì½˜í…ì¸  êµ¬ì¡° ì„¤ê³„ (Mockup)"""
        logger.info("Step 2: ì½˜í…ì¸  êµ¬ì¡° ì„¤ê³„ ì‹œì‘...")
        prompt_template = self.prompts.get('prompt2-structure', {}).get('prompt', '')
        
        # --- Mockup ë¡œì§ ---
        # ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹ , í”„ë¡¬í”„íŠ¸ì™€ ì´ì „ ë‹¨ê³„ ê²°ê³¼ë¥¼ ì¡°í•©í•˜ì—¬ Mockup ê²°ê³¼ ìƒì„±
        # logger.info(f"API Key 'GEMINI_API_KEY' ì‚¬ìš© ì˜ˆì •: {self.gemini_api_key[:5]}...")
        logger.info("ì‹¤ì œ Gemini API í˜¸ì¶œì€ ìƒëµí•©ë‹ˆë‹¤ (Mockup).")

        # í”„ë¡¬í”„íŠ¸ì— ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì‚½ì… (ì‹œë®¬ë ˆì´ì…˜)
        full_prompt = prompt_template.format(research_result=research_result)
        
        mock_result = f"""
# ë¸”ë¡œê·¸ ê¸€ êµ¬ì¡° (Mockup)

ì•„ë˜ëŠ” Gemini APIë¥¼ í†µí•´ ìƒì„±ëœ Mockup êµ¬ì¡°ì…ë‹ˆë‹¤.

---
{full_prompt}
---

## ì œì•ˆëœ êµ¬ì¡°

### 1. ì„œë¡ 
- AI ê¸°ìˆ ì´ ìš°ë¦¬ ì‚¶ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ ìµœì‹  ë™í–¥ì— ëŒ€í•œ ê´€ì‹¬ í™˜ê¸°
- ìƒì„±í˜• AIê°€ ê°€ì ¸ì˜¬ ë¯¸ë˜ì— ëŒ€í•œ ê¸°ëŒ€ê° ì¡°ì„±

### 2. ë³¸ë¡ 

#### 2.1. ì´ˆê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì§„í™”
- GPT-3ë¶€í„° Geminiê¹Œì§€ì˜ ë°œì „ ê³¼ì •
- LLMì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— í™œìš©ë˜ëŠ” ì‹¤ì œ ì‚¬ë¡€ ì†Œê°œ

#### 2.2. ë©€í‹°ëª¨ë‹¬ AIì˜ ì‹œëŒ€
- í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ ì´ë¯¸ì§€ì™€ ì†Œë¦¬ë¥¼ ì´í•´í•˜ëŠ” AI
- DALL-E, Midjourney ë“± ì´ë¯¸ì§€ ìƒì„± AIì˜ ì›ë¦¬ì™€ ê°€ëŠ¥ì„±

#### 2.3. AI ìœ¤ë¦¬ì™€ ë¯¸ë˜ ê³¼ì œ
- AI ë°œì „ì— ë”°ë¥¸ ì‚¬íšŒì , ìœ¤ë¦¬ì  ë”œë ˆë§ˆ
- ì•ìœ¼ë¡œ ìš°ë¦¬ê°€ ì¤€ë¹„í•´ì•¼ í•  ê²ƒë“¤

### 3. ê²°ë¡ 
- AI ê¸°ìˆ ì˜ ë¯¸ë˜ ì „ë§ ìš”ì•½
- ë…ìë“¤ì´ AI ì‹œëŒ€ë¥¼ ì–´ë–»ê²Œ ë§ì´í•´ì•¼ í• ì§€ì— ëŒ€í•œ ì œì–¸
"""
        self._save_result("step2", "step2-structure-kr", mock_result)
        logger.info("Step 2 ì™„ë£Œ.")
        return mock_result

    async def step3_content(self, research_result: str, structure_result: str):
        """Step 3: ì½˜í…ì¸  ì‘ì„±, ì´ë¯¸ì§€ ìƒì„±, í‘œí˜„ êµì • (Mockup)"""
        logger.info("Step 3: ì½˜í…ì¸  ì‘ì„± ì‹œì‘...")
        prompt_data = self.prompts.get('prompt3-content', {})
        
        # --- Mockup ë¡œì§ ---
        logger.info("ì‹¤ì œ Gemini API (ì½˜í…ì¸  ì‘ì„±) í˜¸ì¶œì€ ìƒëµí•©ë‹ˆë‹¤ (Mockup).")
        
        # í”„ë¡¬í”„íŠ¸ì— ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì‚½ì… (ì‹œë®¬ë ˆì´ì…˜)
        full_prompt = prompt_data.get('prompt', '').format(
            research_result=research_result,
            structure_result=structure_result
        )
        
        mock_content = f"""
# AI ê¸°ìˆ ì˜ ë¯¸ë˜: ìƒì„±í˜• AIê°€ ê°€ì ¸ì˜¬ ë³€í™” (Mockup)

## ì„œë¡ 
AI ê¸°ìˆ ì€ ë¹ ë¥´ê²Œ ë°œì „í•˜ë©° ìš°ë¦¬ ì‚¶ì˜ ëª¨ë“  ì˜ì—­ì— ê¹Šì€ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ìµœê·¼ ëª‡ ë…„ê°„ ìƒì„±í˜• AIì˜ ë“±ì¥ì€ ê¸°ìˆ ì˜ íŒ¨ëŸ¬ë‹¤ì„ì„ ê·¼ë³¸ì ìœ¼ë¡œ ë°”ê¾¸ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ê¸€ì—ì„œëŠ” ìµœì‹  AI ê¸°ìˆ  ë™í–¥ê³¼ ìƒì„±í˜• AIê°€ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, ê·¸ë¦¬ê³  ë¯¸ë˜ ì „ë§ì— ëŒ€í•´ ì‹¬ì¸µì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.

## ë³¸ë¡ 

### 1. ì´ˆê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì§„í™”
LLMì€ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì¸ê°„ê³¼ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” AI ëª¨ë¸ì…ë‹ˆë‹¤. GPT-3, GPT-4, ê·¸ë¦¬ê³  êµ¬ê¸€ì˜ Geminiì™€ ê°™ì€ ëª¨ë¸ë“¤ì€ ë‹¨ìˆœí•œ ì •ë³´ ê²€ìƒ‰ì„ ë„˜ì–´, ì°½ì˜ì ì¸ ê¸€ì“°ê¸°, ì½”ë“œ ìƒì„±, ë³µì¡í•œ ë¬¸ì œ í•´ê²° ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë†€ë¼ìš´ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
![image_placeholder_1](images/001.jpg)
ì´ëŸ¬í•œ LLMì˜ ë°œì „ì€ ì •ë³´ ì ‘ê·¼ì„±ì„ ë†’ì´ê³ , ì½˜í…ì¸  ìƒì‚° ë°©ì‹ì„ í˜ì‹ í•˜ë©°, ìƒˆë¡œìš´ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒë¥¼ ì°½ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì—…ë“¤ì€ LLMì„ í™œìš©í•˜ì—¬ ê³ ê° ì„œë¹„ìŠ¤ ìë™í™”, ë§ˆì¼€íŒ… ì½˜í…ì¸  ìƒì„±, ì—°êµ¬ ê°œë°œ ê°€ì†í™” ë“± ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ê²½ìŸë ¥ì„ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### 2. ë©€í‹°ëª¨ë‹¬ AIì˜ ì‹œëŒ€
í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ LLMì„ ë„˜ì–´, ì´ì œ AIëŠ” ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ë©€í‹°ëª¨ë‹¬(Multimodal) ì‹œëŒ€ë¡œ ì§„ì…í•˜ê³  ìˆìŠµë‹ˆë‹¤. êµ¬ê¸€ì˜ GeminiëŠ” í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ë©° ë”ìš± ë³µì¡í•˜ê³  í˜„ì‹¤ì ì¸ ìƒí˜¸ì‘ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
![image_placeholder_2](images/002.jpg)
DALL-E, Midjourneyì™€ ê°™ì€ ì´ë¯¸ì§€ ìƒì„± AIëŠ” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ê³ í’ˆì§ˆì˜ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚´ë©° ì˜ˆìˆ , ë””ìì¸, ê´‘ê³  ë¶„ì•¼ì— í˜ëª…ì„ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë©€í‹°ëª¨ë‹¬ AIëŠ” ì¸ê°„ì˜ ì°½ì˜ì„±ì„ ì¦í­ì‹œí‚¤ê³ , ì´ì „ì—ëŠ” ìƒìƒí•˜ê¸° ì–´ë ¤ì› ë˜ ìƒˆë¡œìš´ í˜•íƒœì˜ ì½˜í…ì¸ ì™€ ì„œë¹„ìŠ¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.

### 3. AI ìœ¤ë¦¬ì™€ ë¯¸ë˜ ê³¼ì œ
AI ê¸°ìˆ ì˜ ë°œì „ì€ ê¸ì •ì ì¸ ë³€í™”ì™€ í•¨ê»˜ ìœ¤ë¦¬ì , ì‚¬íšŒì  ê³¼ì œë„ ë˜ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë”¥í˜ì´í¬ì™€ ê°™ì€ ê¸°ìˆ  ì˜¤ìš© ë¬¸ì œ, AIë¡œ ì¸í•œ ì¼ìë¦¬ ë³€í™”, ë°ì´í„° í¸í–¥ì„± ë¬¸ì œ ë“±ì´ ëŒ€í‘œì ì…ë‹ˆë‹¤.
![image_placeholder_3](images/003.jpg)
ë”°ë¼ì„œ AI ê¸°ìˆ  ê°œë°œê³¼ í•¨ê»˜ íˆ¬ëª…ì„±, ê³µì •ì„±, ì±…ì„ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ê³¼ ê·œì œ ë§ˆë ¨ì´ ì‹œê¸‰í•©ë‹ˆë‹¤. ê¸°ìˆ  ê°œë°œì, ì •ì±… ì…ì•ˆì, ì‚¬íšŒ êµ¬ì„±ì› ëª¨ë‘ê°€ í˜‘ë ¥í•˜ì—¬ AIê°€ ì¸ë¥˜ì—ê²Œ ì´ë¡œìš´ ë°©í–¥ìœ¼ë¡œ ë°œì „í•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.

## ê²°ë¡ 
ìƒì„±í˜• AIë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ìµœì‹  AI ê¸°ìˆ ì€ ì¸ë¥˜ì—ê²Œ ì „ë¡€ ì—†ëŠ” ê¸°íšŒë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ìˆ ì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ë©´ì„œë„, ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ë“¤ì„ í˜„ëª…í•˜ê²Œ í•´ê²°í•´ ë‚˜ê°„ë‹¤ë©´, ìš°ë¦¬ëŠ” ë”ìš± í’ìš”ë¡­ê³  í˜ì‹ ì ì¸ ë¯¸ë˜ë¥¼ ë§ì´í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ì§€ì†ì ì¸ ì—°êµ¬ì™€ ì‚¬íšŒì  ë…¼ì˜ë¥¼ í†µí•´ AIê°€ ëª¨ë‘ì—ê²Œ ì´ë¡œìš´ ê¸°ìˆ ë¡œ ìë¦¬ë§¤ê¹€í•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
"""
        self._save_result("step3", "step3-content-kr", mock_content)
        
        # ì´ë¯¸ì§€ ìƒì„± (Mockup)
        image_paths = await self._generate_images(mock_content)
        
        # í‘œí˜„ êµì • (Mockup)
        revised_content_w_feedback, revised_content_final = await self._revise_content(mock_content)
        
        self._save_result("step3", "step3-revised-w.feedback-kr", revised_content_w_feedback)
        self._save_result("step3", "step3-revised-final-kr", revised_content_final)

        # HTML ë³€í™˜ (Mockup)
        await self._convert_to_html(revised_content_final, "AI ê¸°ìˆ ì˜ ë¯¸ë˜: ìƒì„±í˜• AIê°€ ê°€ì ¸ì˜¬ ë³€í™”")
        
        logger.info("Step 3 ì™„ë£Œ.")
        return revised_content_final

    async def _generate_images(self, content: str):
        """ì´ë¯¸ì§€ ìƒì„± (Mockup)"""
        logger.info("ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (Mockup)...")
        # ì½˜í…ì¸ ì—ì„œ ì´ë¯¸ì§€ í”Œë ˆì´ìŠ¤í™€ë” ì¶”ì¶œ (ì •ê·œì‹ ì‚¬ìš©)
        import re
        image_placeholders = re.findall(r'!(?P<alt>\[.*?\])\((?P<path>images/\d{3}\.jpg)\)', content)
        
        generated_image_paths = []
        for i, (alt_text, path) in enumerate(image_placeholders):
            # ì‹¤ì œ Nano Banana API í˜¸ì¶œ ëŒ€ì‹  Mockup ì´ë¯¸ì§€ ìƒì„± ì‹œë®¬ë ˆì´ì…˜
            image_name = f"step3-image-{str(i+1).zfill(3)}.jpg"
            image_dir = self.output_dir / "step3" / "images"
            image_dir.mkdir(parents=True, exist_ok=True)
            mock_image_path = image_dir / image_name
            
            # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ìƒì„± ëŒ€ì‹ , íŒŒì¼ì´ ìƒì„±ë˜ì—ˆë‹¤ê³  ê°€ì •
            with open(mock_image_path, 'w', encoding='utf-8') as f:
                f.write(f"Mockup Image Content for {alt_text} - {image_name}")
            
            generated_image_paths.append(str(mock_image_path))
            logger.info(f"Mockup ì´ë¯¸ì§€ ìƒì„±: {mock_image_path}")
        
        logger.info("ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (Mockup).")
        return generated_image_paths

    async def _revise_content(self, original_content: str):
        """ì½˜í…ì¸  í‘œí˜„ êµì • (Mockup)"""
        logger.info("ì½˜í…ì¸  í‘œí˜„ êµì • ì‹œì‘ (Mockup)...")
        prompt_data = self.prompts.get('prompt3-revision', {})
        
        # --- Mockup ë¡œì§ ---
        logger.info("ì‹¤ì œ Claude API í˜¸ì¶œì€ ìƒëµí•©ë‹ˆë‹¤ (Mockup).")
        
        # ì›ë³¸ ì½˜í…ì¸ ì— êµì • ì˜ê²¬ì„ ì¶”ê°€í•˜ëŠ” Mockup
        revised_w_feedback = f"""
{original_content}

<!-- êµì • ì˜ê²¬: ì„œë¡ ì˜ ë¬¸ì¥ì„ ì¢€ ë” ê°„ê²°í•˜ê²Œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. -->
<!-- êµì • ì˜ê²¬: 'ë†€ë¼ìš´ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤'ë¥¼ 'ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì…ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤'ë¡œ ë³€ê²½í•˜ì—¬ í‘œí˜„ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤. -->
<!-- êµì • ì˜ê²¬: 'AI ìœ¤ë¦¬ì™€ ë¯¸ë˜ ê³¼ì œ' ì„¹ì…˜ì—ì„œ ë¬¸ë‹¨ ê°„ì˜ ì—°ê²°ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì—ˆìŠµë‹ˆë‹¤. -->
"""
        # ìµœì¢… ë³¸ë¬¸ì€ êµì • ì˜ê²¬ì´ ì—†ëŠ” ë²„ì „
        revised_final = original_content.replace("ë†€ë¼ìš´ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤", "ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì…ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤")
        revised_final += "\n\n(ì´ê²ƒì€ êµì •ëœ ìµœì¢… ë³¸ë¬¸ Mockupì…ë‹ˆë‹¤.)"
        
        logger.info("ì½˜í…ì¸  í‘œí˜„ êµì • ì™„ë£Œ (Mockup).")
        return revised_w_feedback, revised_final

    async def _convert_to_html(self, content_body: str, title: str):
        """Markdown ì½˜í…ì¸ ë¥¼ HTMLë¡œ ë³€í™˜ (Mockup)"""
        logger.info("HTML ë³€í™˜ ì‹œì‘ (Mockup)...")
        template_path = Path("./templates/content-template.html")
        if not template_path.exists():
            logger.error(f"HTML í…œí”Œë¦¿ íŒŒì¼ '{template_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        with open(template_path, 'r', encoding='utf-8') as f:
            html_template = f.read()

        # Markdown to HTML ë³€í™˜ (ì‹¤ì œë¡œëŠ” markdown2 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¥¼ HTML íƒœê·¸ë¡œ ë³€í™˜í•˜ëŠ” Mockup
        html_content_body = content_body.replace("# ", "<h1>").replace("## ", "<h2>").replace("### ", "<h3>")
        html_content_body = html_content_body.replace("</h1>", "</h1>").replace("</h2>", "</h2>").replace("<h3>", "</h3>")
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ì—…ë°ì´íŠ¸ (Mockup)
        html_content_body = html_content_body.replace("images/", f"./step3/images/")

        final_html = html_template.format(
            title=title,
            published_date=datetime.now().strftime("%Y-%m-%d"),
            content_body=html_content_body
        )
        
        self._save_result("step3", "step3-final-kr", final_html, extension='html')
        logger.info("HTML ë³€í™˜ ì™„ë£Œ (Mockup).")

    async def step4_social(self, blog_content: str):
        """Step 4: SNS ì½˜í…ì¸  ë³€í™˜ (Mockup)"""
        logger.info("Step 4: SNS ì½˜í…ì¸  ë³€í™˜ ì‹œì‘...")
        prompt_data = self.prompts.get('prompt4-social', {})

        # --- Mockup ë¡œì§ ---
        logger.info("ì‹¤ì œ Gemini API (SNS ì½˜í…ì¸  ë³€í™˜) í˜¸ì¶œì€ ìƒëµí•©ë‹ˆë‹¤ (Mockup).")

        full_prompt = prompt_data.get('prompt', '').format(blog_content=blog_content)

        mock_social_content = f"""
# ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ (Mockup)

---
{full_prompt}
---

âœ¨ AI ê¸°ìˆ ì˜ ë¯¸ë˜, ìƒì„±í˜• AIê°€ ê°€ì ¸ì˜¬ ë†€ë¼ìš´ ë³€í™”! âœ¨

ìµœì‹  AI íŠ¸ë Œë“œì™€ í•¨ê»˜ ìš°ë¦¬ ì‚¶ì´ ì–´ë–»ê²Œ í˜ì‹ ë ì§€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ğŸ¤”
ë¸”ë¡œê·¸ì—ì„œ ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•˜ê³ , AI ì‹œëŒ€ì˜ ì£¼ì¸ê³µì´ ë˜ì–´ë³´ì„¸ìš”!

#AIê¸°ìˆ  #ìƒì„±í˜•AI #ë¯¸ë˜ê¸°ìˆ  #ì¸ê³µì§€ëŠ¥ #ê¸°ìˆ íŠ¸ë Œë“œ #í˜ì‹  #AIì‹œëŒ€ #ë¸”ë¡œê·¸í¬ìŠ¤íŠ¸

ğŸ”— ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ê¸°: [ë¸”ë¡œê·¸ ë§í¬]
"""
        self._save_result("step4", "step4-social-kr", mock_social_content)
        logger.info("Step 4 ì™„ë£Œ.")
        return mock_social_content

    async def run_pipeline(self):
        """ì „ì²´ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("ì½˜í…ì¸  ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘.")
        try:
            self.output_dir.mkdir(parents=True, exist_ok=True)
            
            # ë‹¨ê³„ë³„ ì‹¤í–‰
            research_result = await self.step1_research()
            structure_result = await self.step2_structure(research_result)
            
            content_final_result = await self.step3_content(research_result, structure_result)
            
            social_content_result = await self.step4_social(content_final_result)
            
            logger.info(f"âœ“ íŒŒì´í”„ë¼ì¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ. ê²°ê³¼ë¬¼ì€ '{self.output_dir}' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
        except Exception as e:
            logger.error(f"âœ— íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì§€ì 
if __name__ == "__main__":
    pipeline = ContentAutomationPipeline()
    asyncio.run(pipeline.run_pipeline())
